# ğŸ—£ï¸ OpenAI Whisper Speech-to-Text Formatter ğŸ§

This project provides a simple and elegant interface for transcribing audio files into readable text using OpenAI's Whisper model. Built with Python and Gradio, it offers a streamlined workflow where users can upload audio files, input their API key, and instantly receive structured, speaker-labeled transcripts â€” especially tailored for courtroom or dialogue-heavy settings.

---

## ğŸš€ Features

- ğŸ™ï¸ **Audio Upload**: Upload your own audio recordings.
- ğŸ¤– **OpenAI Whisper Integration**: Utilizes OpenAIâ€™s `whisper-1` model for high-quality transcription.
- ğŸ§  **Custom Speaker Labeling**:
  - Sentences with a question (`?`) are labeled as:
    ```
    Q	 What is your name?
    A	 John Doe.
    ```
  - Default fallback labeling as `THE COURT:` if no Q/A logic applies.
- ğŸ›¡ï¸ **Secure API Handling**: Enter your OpenAI API key securely through a masked input.
- ğŸŒ **Gradio Web UI**: User-friendly interface to interact with the transcription engine directly in your browser.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ .gitignore           # Ignores 'venv/' and 'Others/' folders
â”œâ”€â”€ requirements.txt     # All Python dependencies
â”œâ”€â”€ speech_to_text.py    # Main Python script containing logic & interface
â”œâ”€â”€ venv/                # (Ignored) Your Python virtual environment
â”œâ”€â”€ Others/              # (Ignored) Any additional unused resources
```

---

## ğŸ§ª Dependencies

Install all required dependencies using:

```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Setup & Usage

1. **Clone the repository:**

```bash
git clone https://github.com/Ajacent4sure/Audio-to-Text
```

2. **Create a `.env` file** *(optional but recommended)* to store your OpenAI key:

```
OPENAI_API_KEY=your-api-key-here
```

3. **Run the app:**

```bash
python speech_to_text.py
```

4. **In the Gradio interface:**
   - Upload an audio file.
   - Enter your OpenAI API key.
   - Click "Transcribe" to get your Q/A-labeled transcript.

---

## ğŸ§  Example Output

```
Q	 What time did you arrive at the scene?
A	 I arrived around 10:30 AM.
THE COURT: Thank you, Counsel.
Q	 Were there any witnesses present?
A	 Yes, a bystander was present.
```

---

## ğŸ› ï¸ Tech Stack

- Python ğŸ
- OpenAI Whisper API ğŸ§ 
- Gradio ğŸ¨

---

## âœ… To-Do

- [ ] Add audio playback with transcript syncing
- [ ] Export transcript to `.docx` or `.pdf`
- [ ] Add support for batch audio processing

---


---

## ğŸ™Œ Acknowledgments

Built with â¤ï¸ for voice transcription enthusiasts and legal tech developers, powered by OpenAI's Whisper model and Gradio.
